{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DfOsH9u57rja",
    "outputId": "5da52ee4-efa9-4b43-f756-e9c5d84c640e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-15 03:21:05--  https://raw.githubusercontent.com/iamsli/cs230-final-project/main/data/en-valid-all-test.txt?token=AHEDSMEMC4HBI3P3RF7SLJLAVAXN6\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5565536 (5.3M) [text/plain]\n",
      "Saving to: ‘en-valid-all-test.txt?token=AHEDSMEMC4HBI3P3RF7SLJLAVAXN6’\n",
      "\n",
      "en-valid-all-test.t 100%[===================>]   5.31M  3.32MB/s    in 1.6s    \n",
      "\n",
      "2021-05-15 03:21:07 (3.32 MB/s) - ‘en-valid-all-test.txt?token=AHEDSMEMC4HBI3P3RF7SLJLAVAXN6’ saved [5565536/5565536]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/iamsli/cs230-final-project/main/data/en-valid-all-test.txt?token=AHEDSMEMC4HBI3P3RF7SLJLAVAXN6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tVW15K9q7sbf",
    "outputId": "81667bae-07a0-4dcf-f997-e9451687c569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-15 03:21:07--  https://raw.githubusercontent.com/iamsli/cs230-final-project/main/data/en-valid-all-train.txt?token=AHEDSMAFRNHAYWV7ZE3NHATAVAYAE\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 25044403 (24M) [text/plain]\n",
      "Saving to: ‘en-valid-all-train.txt?token=AHEDSMAFRNHAYWV7ZE3NHATAVAYAE’\n",
      "\n",
      "en-valid-all-train. 100%[===================>]  23.88M  6.21MB/s    in 5.6s    \n",
      "\n",
      "2021-05-15 03:21:13 (4.30 MB/s) - ‘en-valid-all-train.txt?token=AHEDSMAFRNHAYWV7ZE3NHATAVAYAE’ saved [25044403/25044403]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/iamsli/cs230-final-project/main/data/en-valid-all-train.txt?token=AHEDSMAFRNHAYWV7ZE3NHATAVAYAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BTg4s1PG6Qec"
   },
   "outputs": [],
   "source": [
    "!mv en-valid-all-train.txt?token=AHEDSMAFRNHAYWV7ZE3NHATAVAYAE en-valid-all-train.txt\n",
    "!mv en-valid-all-test.txt?token=AHEDSMEMC4HBI3P3RF7SLJLAVAXN6 en-valid-all-test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DneYaIjL7y3V",
    "outputId": "e02e8340-bd54-4649-96ce-ea2c1ee76efe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('using device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kB_sjSgg-43E"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "lr = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8paqDgdYrEqh"
   },
   "outputs": [],
   "source": [
    "# def additional_preprocess(raw_data):\n",
    "#   full_data = []\n",
    "#   for i in raw_data:\n",
    "#     i = i.lower()\n",
    "#     i = i.replace('\\n')\n",
    "#     i = i.translate(str.maketrans('', '', string.punctuation))\n",
    "#     if '\\t' in i:\n",
    "#       tmp = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "G6b5dRRDi07j"
   },
   "outputs": [],
   "source": [
    "with open('en-valid-all-test.txt', 'r') as f:\n",
    "  raw_test = f.readlines()\n",
    "\n",
    "with open('en-valid-all-train.txt', 'r') as f:\n",
    "  raw_train = f.readlines()\n",
    "\n",
    "def get_mapping(sentence):\n",
    "  indices = [word_to_idx[i] for i in sentence]\n",
    "  return torch.tensor(indices)\n",
    "\n",
    "def get_vocab(raw_list):\n",
    "  dataset = []\n",
    "  for i in raw_list:\n",
    "    i = i.lower()\n",
    "    i = i.replace('\\t', '')\n",
    "    i = i.replace('\\n', '')\n",
    "    i = i.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    dataset.extend(i.split(' '))\n",
    "  dataset = list(set(dataset))\n",
    "\n",
    "  #add 1 to never get 0\n",
    "  word_to_idx = {w: i+1 for i, w in enumerate(dataset)}\n",
    "  idx_to_word = {i+1: w for i, w in enumerate(dataset)}\n",
    "\n",
    "  return word_to_idx, idx_to_word\n",
    "\n",
    "word_to_idx, idx_to_word = get_vocab(raw_train + raw_test)\n",
    "vocab_size = len(word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9S8Q_iHz8dTw"
   },
   "outputs": [],
   "source": [
    "def get_longest_sentence(raw_data):\n",
    "  longest = 0\n",
    "  for i in raw_data:\n",
    "    curr_len = len(i.split(' '))\n",
    "    if curr_len > longest:\n",
    "      longest = curr_len\n",
    "\n",
    "  return longest\n",
    "\n",
    "longest_sentence = get_longest_sentence(raw_train + raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PBHLQtEin40Z"
   },
   "outputs": [],
   "source": [
    "def get_dataset(raw_data, label_number = 1):\n",
    "  inputs = []\n",
    "  outputs = []\n",
    "  for i in raw_data:\n",
    "    i = i.lower()\n",
    "    i = i.replace('\\t', '')\n",
    "    i = i.replace('\\n', '')\n",
    "    i = i.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    tmp = i.split(' ')\n",
    "    string_so_far = []\n",
    "    for index, data in enumerate(tmp):\n",
    "      if not index + label_number == len(tmp):\n",
    "        string_so_far.append(data)\n",
    "        encoding = get_mapping(string_so_far)\n",
    "        zeros_length = longest_sentence - len(string_so_far)\n",
    "        padded_encoding = torch.cat((encoding, torch.zeros(zeros_length)))\n",
    "        inputs.append(padded_encoding)\n",
    "        outputs.append(get_mapping(tmp[index + 1:index + label_number + 1]))\n",
    "\n",
    "  ds = TensorDataset(torch.stack(inputs), torch.stack(outputs))\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "IaLO3fCg6Gbv"
   },
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(raw_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ts9cpB2eGCCj",
    "outputId": "38f4805f-f387-4c39-ec1c-ab38decd1dce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4498583"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "VHU8Bczp-Nwv"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "9doLeaM5EPzl"
   },
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "  def __init__(self, embedding_dim, hidden_dim, vocab_size, longest_sentence, output_size = 1):\n",
    "    super(generator, self).__init__()\n",
    "    self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "    self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "    self.linear = nn.Linear(hidden_dim * longest_sentence, vocab_size)\n",
    "\n",
    "  def forward(self, input_sentence):\n",
    "    embeds = self.embeddings(input_sentence)\n",
    "    lstm_out, _ = self.lstm(embeds)\n",
    "    output = self.linear(lstm_out.view(input_sentence.shape[0], -1))\n",
    "    output = F.softmax(output, dim = 0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "BSj-PuoNYuUH"
   },
   "outputs": [],
   "source": [
    "model = generator(128, 128, vocab_size, longest_sentence, output_size = 1)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "hfZkzL9W-tO8"
   },
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "  for index, data in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    x = data[0].to(device)\n",
    "    y = data[1].to(device)\n",
    "\n",
    "    prediction = model(x.long())\n",
    "    loss = criterion(prediction.squeeze(), y.squeeze())\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bn8hsy3z_1TK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM Language Generation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
