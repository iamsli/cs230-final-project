{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM Language Generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfOsH9u57rja",
        "outputId": "5da52ee4-efa9-4b43-f756-e9c5d84c640e"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/iamsli/cs230-final-project/main/data/en-valid-all-test.txt?token=AHEDSMEMC4HBI3P3RF7SLJLAVAXN6"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-15 03:21:05--  https://raw.githubusercontent.com/iamsli/cs230-final-project/main/data/en-valid-all-test.txt?token=AHEDSMEMC4HBI3P3RF7SLJLAVAXN6\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5565536 (5.3M) [text/plain]\n",
            "Saving to: ‘en-valid-all-test.txt?token=AHEDSMEMC4HBI3P3RF7SLJLAVAXN6’\n",
            "\n",
            "en-valid-all-test.t 100%[===================>]   5.31M  3.32MB/s    in 1.6s    \n",
            "\n",
            "2021-05-15 03:21:07 (3.32 MB/s) - ‘en-valid-all-test.txt?token=AHEDSMEMC4HBI3P3RF7SLJLAVAXN6’ saved [5565536/5565536]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVW15K9q7sbf",
        "outputId": "81667bae-07a0-4dcf-f997-e9451687c569"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/iamsli/cs230-final-project/main/data/en-valid-all-train.txt?token=AHEDSMAFRNHAYWV7ZE3NHATAVAYAE"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-15 03:21:07--  https://raw.githubusercontent.com/iamsli/cs230-final-project/main/data/en-valid-all-train.txt?token=AHEDSMAFRNHAYWV7ZE3NHATAVAYAE\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25044403 (24M) [text/plain]\n",
            "Saving to: ‘en-valid-all-train.txt?token=AHEDSMAFRNHAYWV7ZE3NHATAVAYAE’\n",
            "\n",
            "en-valid-all-train. 100%[===================>]  23.88M  6.21MB/s    in 5.6s    \n",
            "\n",
            "2021-05-15 03:21:13 (4.30 MB/s) - ‘en-valid-all-train.txt?token=AHEDSMAFRNHAYWV7ZE3NHATAVAYAE’ saved [25044403/25044403]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTg4s1PG6Qec"
      },
      "source": [
        "!mv en-valid-all-train.txt?token=AHEDSMAFRNHAYWV7ZE3NHATAVAYAE en-valid-all-train.txt\n",
        "!mv en-valid-all-test.txt?token=AHEDSMEMC4HBI3P3RF7SLJLAVAXN6 en-valid-all-test.txt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DneYaIjL7y3V",
        "outputId": "e02e8340-bd54-4649-96ce-ea2c1ee76efe"
      },
      "source": [
        "import re\n",
        "import string\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('using device: {}'.format(device))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using device: cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB_sjSgg-43E"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 10\n",
        "lr = 0.003"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8paqDgdYrEqh"
      },
      "source": [
        "# def additional_preprocess(raw_data):\n",
        "#   full_data = []\n",
        "#   for i in raw_data:\n",
        "#     i = i.lower()\n",
        "#     i = i.replace('\\n')\n",
        "#     i = i.translate(str.maketrans('', '', string.punctuation))\n",
        "#     if '\\t' in i:\n",
        "#       tmp = "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6b5dRRDi07j"
      },
      "source": [
        "with open('en-valid-all-test.txt', 'r') as f:\n",
        "  raw_test = f.readlines()\n",
        "\n",
        "with open('en-valid-all-train.txt', 'r') as f:\n",
        "  raw_train = f.readlines()\n",
        "\n",
        "def get_mapping(sentence):\n",
        "  indices = [word_to_idx[i] for i in sentence]\n",
        "  return torch.tensor(indices)\n",
        "\n",
        "def get_vocab(raw_list):\n",
        "  dataset = []\n",
        "  for i in raw_list:\n",
        "    i = i.lower()\n",
        "    i = i.replace('\\t', '')\n",
        "    i = i.replace('\\n', '')\n",
        "    i = i.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    dataset.extend(i.split(' '))\n",
        "  dataset = list(set(dataset))\n",
        "\n",
        "  word_to_idx = {}\n",
        "  idx_to_word = {}\n",
        "\n",
        "  #add 1 to never get 0\n",
        "  for i, j in enumerate(dataset):\n",
        "    word_to_idx[j] = i + 1\n",
        "    idx_to_word[i + 1] = j\n",
        "  return word_to_idx, idx_to_word\n",
        "\n",
        "word_to_idx, idx_to_word = get_vocab(raw_train + raw_test)\n",
        "vocab_size = len(word_to_idx)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S8Q_iHz8dTw"
      },
      "source": [
        "def get_longest_sentence(raw_data):\n",
        "  longest = 0\n",
        "  for i in raw_data:\n",
        "    curr_len = len(i.split(' '))\n",
        "    if curr_len > longest:\n",
        "      longest = curr_len\n",
        "\n",
        "  return longest\n",
        "\n",
        "longest_sentence = get_longest_sentence(raw_train + raw_test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBHLQtEin40Z"
      },
      "source": [
        "def get_dataset(raw_data, label_number = 1):\n",
        "  inputs = []\n",
        "  outputs = []\n",
        "  for i in raw_data:\n",
        "    i = i.lower()\n",
        "    i = i.replace('\\t', '')\n",
        "    i = i.replace('\\n', '')\n",
        "    i = i.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    tmp = i.split(' ')\n",
        "    string_so_far = []\n",
        "    for index, data in enumerate(tmp):\n",
        "      if not index + label_number == len(tmp):\n",
        "        string_so_far.append(data)\n",
        "        encoding = get_mapping(string_so_far)\n",
        "        zeros_length = longest_sentence - len(string_so_far)\n",
        "        padded_encoding = torch.cat((encoding, torch.zeros(zeros_length)))\n",
        "        inputs.append(padded_encoding)\n",
        "        outputs.append(get_mapping(tmp[index + 1:index + label_number + 1]))\n",
        "\n",
        "  ds = TensorDataset(torch.stack(inputs), torch.stack(outputs))\n",
        "  return ds"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaLO3fCg6Gbv"
      },
      "source": [
        "train_dataset = get_dataset(raw_train, 1)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts9cpB2eGCCj",
        "outputId": "38f4805f-f387-4c39-ec1c-ab38decd1dce"
      },
      "source": [
        "len(train_dataset)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4498583"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHU8Bczp-Nwv"
      },
      "source": [
        "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9doLeaM5EPzl"
      },
      "source": [
        "class generator(nn.Module):\n",
        "  def __init__(self, embedding_dim, hidden_dim, vocab_size, longest_sentence, output_size = 1):\n",
        "    super(generator, self).__init__()\n",
        "    self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "    self.linear = nn.Linear(hidden_dim * longest_sentence, vocab_size)\n",
        "\n",
        "  def forward(self, input_sentence):\n",
        "    embeds = self.embeddings(input_sentence)\n",
        "    lstm_out, _ = self.lstm(embeds)\n",
        "    output = self.linear(lstm_out.view(input_sentence.shape[0], -1))\n",
        "    output = F.softmax(output, dim = 0)\n",
        "    return output"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSj-PuoNYuUH"
      },
      "source": [
        "model = generator(128, 128, vocab_size, longest_sentence, output_size = 1)\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr = lr)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfZkzL9W-tO8"
      },
      "source": [
        "for i in range(epochs):\n",
        "  for index, data in enumerate(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    x = data[0].to(device)\n",
        "    y = data[1].to(device)\n",
        "\n",
        "    prediction = model(x.long())\n",
        "    loss = criterion(prediction.squeeze(), y.squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn8hsy3z_1TK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}